{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwZZvcWOzuxv"
      },
      "outputs": [],
      "source": [
        "# Importing library modules\n",
        "\n",
        "from google.colab import files                               # To download files\n",
        "import numpy as np                                           # For array operation\n",
        "import matplotlib.pyplot as plt                              # For plotting\n",
        "import glob                                                  # To dynamically load data\n",
        "import cv2                                                   # Image related operation\n",
        "from google.colab.patches import cv2                         # For displaying image\n",
        "from tensorflow.keras.preprocessing import image             # Image processing\n",
        "from tensorflow.keras.applications.densenet import DenseNet121     # To import convolution base\n",
        "from tensorflow.keras.applications.densenet import preprocess_input # To preprocess images according to the model\n",
        "from keras.models import Model, Sequential                   # To import model skeleton\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D # To import layer and related methods, classes\n",
        "import os                                                     # To find the path\n",
        "import seaborn as sns                                         # For editing plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCapYE2SpZld",
        "outputId": "af80ab37-d07f-4cad-c25c-637067e3e93a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkJiu9AmzzYB"
      },
      "outputs": [],
      "source": [
        "# Importing data from MyDrive\n",
        "\n",
        "print(os.listdir(\"/content/drive/MyDrive/FINAL(ORG)\"))\n",
        "\n",
        "SIZE = 128\n",
        "\n",
        "Timages = []\n",
        "Tlabels = []\n",
        "for directory_path in glob.glob(\"/content/drive/MyDrive/FINAL(ORG)/*\"):\n",
        "    label = directory_path.split(\"/\")[-1]\n",
        "    print(label)\n",
        "    print(directory_path)\n",
        "    for img_path in glob.glob(os.path.join(directory_path,\"*.*\")):\n",
        "      print(img_path)\n",
        "      img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "      img = cv2.resize(img, (SIZE, SIZE))\n",
        "      img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "      img = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "      Timages.append(img)\n",
        "      Tlabels.append(label)\n",
        "\n",
        "Timages = np.array(Timages)\n",
        "Tlabels = np.array(Tlabels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pG-JIH6z-9b"
      },
      "outputs": [],
      "source": [
        "# Splitting data between training and testing sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# If integer encoding required\n",
        "#x_train, x_val, y_train, y_val = train_test_split(Timages, Tlabels_encoded, test_size=0.33, random_state=42)\n",
        "\n",
        "# If one hot encoding required\n",
        "x_train, x_test, y_train, y_test = train_test_split(Timages, Tlabels, test_size=0.20, random_state=42)\n",
        "#x_train, x_val, y_train, y_val = train_test_split(x_t, y_t, test_size=0.33, random_state=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Llk_6XYL0B1n"
      },
      "outputs": [],
      "source": [
        "#Encode labels from text to integers.\n",
        "\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(y_train)\n",
        "y_train = le.transform(y_train)\n",
        "\n",
        "#le.fit(y_val)\n",
        "#y_val = le.transform(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KneDAn4l0DyY"
      },
      "outputs": [],
      "source": [
        "# Perform one hot encoding\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train)\n",
        "#y_val = to_categorical(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpgykHya0FwO",
        "outputId": "56b7b055-a627-4e49-ed1c-7e3781b21673"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "427\n"
          ]
        }
      ],
      "source": [
        "# Importing pre-trainned cnn 'MobileNetV2'\n",
        "\n",
        "model = DenseNet121(input_shape = (128, 128, 3), weights='imagenet', include_top=False)\n",
        "print(len(model.layers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ipce-mat0JFU"
      },
      "outputs": [],
      "source": [
        "#Add layers for feature extraction in deep learning\n",
        "\n",
        "#activation = 'sigmoid'\n",
        "#'sigmoid'\n",
        "x = model.output\n",
        "feature_layer = Flatten()(x)\n",
        "\n",
        "# Make a new model combining both feature extractor and x\n",
        "cnn_model = Model(inputs=model.input, outputs=feature_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-dZR7Dp0LJX"
      },
      "outputs": [],
      "source": [
        "# Freeznig layers and compiling the model\n",
        "\n",
        "for layers in (cnn_model.layers)[:427]:\n",
        "    print(layers)\n",
        "    layers.trainable = False\n",
        "\n",
        "#cnn_model.compile(optimizer='Adam',loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "print(cnn_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wZj9Xji0Obb",
        "outputId": "7451d888-6643-4e20-85df-3a02cdfe066d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 31s 3s/step\n"
          ]
        }
      ],
      "source": [
        "# Extract the features using the deep learning architecture\n",
        "\n",
        "x_train_feature = cnn_model.predict(x_train) #This is out X input to Machine Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymhpzlha0V9u"
      },
      "outputs": [],
      "source": [
        "# Immport machine learning classifier\n",
        "#from sklearn.neighbors import KNeighborsClassifier\n",
        "#MC_model = KNeighborsClassifier()\n",
        "#from sklearn.ensemble import RandomForestClassifier\n",
        "#MC_model = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
        "#from sklearn.ensemble import AdaBoostClassifier\n",
        "#MC_model = AdaBoostClassifier(n_estimators=100)\n",
        "#from sklearn.ensemble import GradientBoostingClassifier\n",
        "#MC_model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "MC_model = LogisticRegression(random_state=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DQm9JlE2sKB"
      },
      "outputs": [],
      "source": [
        "# Inverse transform training labels\n",
        "\n",
        "y_train = np.argmax(y_train,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPwYVsS40fyw"
      },
      "outputs": [],
      "source": [
        "# Train the model on training data\n",
        "\n",
        "MC_model.fit(x_train_feature, y_train)                # x - Image, y - Label\n",
        "\n",
        "X_test_feature = cnn_model.predict(x_test)\n",
        "prediction_MC_Unravel = MC_model.predict(X_test_feature)\n",
        "prediction_MC = prediction_MC_Unravel\n",
        "print(prediction_MC)\n",
        "prediction_MC = le.inverse_transform(prediction_MC)\n",
        "print(len(x_test))\n",
        "print(prediction_MC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsnR5-Wi3Ijw"
      },
      "outputs": [],
      "source": [
        "# Draw learning curves with cross-validation\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from yellowbrick.model_selection import LearningCurve\n",
        "\n",
        "# Input the data\n",
        "X = x_train_feature\n",
        "y_train_decoded = y_train\n",
        "y = y_train_decoded\n",
        "\n",
        "# Create the learning curve visualizer\n",
        "cv = 4\n",
        "#cv = StratifiedKFold(n_splits=12)\n",
        "sizes = np.linspace(0.1, 1.0, 20)\n",
        "\n",
        "# Instantiate the classification model and visualizer\n",
        "fig = plt.figure(figsize=(6,4))\n",
        "ax = fig.add_subplot(111)\n",
        "for axis in ['top', 'bottom', 'left', 'right']:\n",
        "    ax.spines[axis].set_linewidth(4)\n",
        "    ax.spines[axis].set_color('brown')\n",
        "\n",
        "plt.xticks(fontsize=17,weight='bold')\n",
        "plt.yticks(fontsize=17,weight='bold')\n",
        "\n",
        "#ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
        "\n",
        "visualizer = LearningCurve(MC_model, cv=cv, scoring='accuracy', train_sizes=sizes, ax=ax, kws = {'linewidths': [100,100]})\n",
        "visualizer.fit(X, y)        # Fit the data to the visualizer\n",
        "\n",
        "visualizer.ax.set_xlabel('Training instances',fontsize=25,color='brown',weight='bold')\n",
        "visualizer.ax.set_ylabel('Score',fontsize=25,color='brown',weight='bold')\n",
        "visualizer.ax.set_title('DenseNet121+LR',fontsize=25,color='brown',weight='bold')\n",
        "plt.xticks(fontsize=17,weight='bold')\n",
        "plt.yticks(fontsize=17,weight='bold')\n",
        "plt.legend(loc=(0.56,0.03), frameon=True, prop={'size':10,'weight':'bold'})\n",
        "\n",
        "plt.savefig(\"DenseNet121+LR.pdf\", bbox_inches='tight')\n",
        "files.download(\"DenseNet121+LR.pdf\")\n",
        "\n",
        "visualizer.show()           # Finalize and render the figure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qo3KtnIuSkrG"
      },
      "outputs": [],
      "source": [
        "#Print overall accuracy\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(len(y_test))\n",
        "print(len(prediction_MC))\n",
        "print (\"Accuracy = \", metrics.accuracy_score(y_test, prediction_MC))\n",
        "\n",
        "#Confusion Matrix - verify accuracy of each class\n",
        "cm = confusion_matrix(y_test, prediction_MC)\n",
        "\n",
        "accuracy=metrics.accuracy_score(y_test,prediction_MC)\n",
        "precision_positive=metrics.precision_score(y_test,prediction_MC,pos_label='Smoke_A')\n",
        "print('precision=',precision_positive)\n",
        "recall_sensitivity=metrics.recall_score(y_test,prediction_MC,pos_label='Smoke_A')\n",
        "print('Recall=',recall_sensitivity)\n",
        "f1_positive=metrics.f1_score(y_test,prediction_MC,pos_label='Smoke_A')\n",
        "print('F1-score=',f1_positive)\n",
        "hamming_loss=metrics.hamming_loss(y_test, prediction_MC)\n",
        "print('hamming loss=',hamming_loss)\n",
        "\n",
        "#jaccard_score=metrics.jaccard_score(y_test_metric, prediction_MC_metric)\n",
        "#print('jaccard score=',jaccard_score)\n",
        "x_test_feat=cnn_model.predict(x_test)\n",
        "y_test_prob=MC_model.predict_proba(x_test_feat)\n",
        "cross_entropy_loss=metrics.log_loss(y_test,y_test_prob)\n",
        "print('Cross entropy Loss=',cross_entropy_loss)\n",
        "\n",
        "#print(cm)\n",
        "sns.heatmap(cm, annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJRXU-mUULpW"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "\n",
        "X_test_feature = cnn_model.predict(x_test)\n",
        "y_scores = MC_model.predict_proba(X_test_feature)\n",
        "#print(y_scores[0])\n",
        "#print(y_test)\n",
        "#print(y_scores[1])\n",
        "#print(y_test)\n",
        "\n",
        "le.fit(y_test)\n",
        "y_test_trans = le.transform(y_test)\n",
        "#print(y_test)\n",
        "\n",
        "fig = plt.figure(figsize=(6,4))\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "for axis in ['top', 'bottom', 'left', 'right']:\n",
        "  ax.spines[axis].set_linewidth(5)\n",
        "  ax.spines[axis].set_color('black')\n",
        "\n",
        "fpr, tpr, threshold = roc_curve(y_test_trans, y_scores[:,1])\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.xticks(fontsize=20,weight='bold')\n",
        "plt.yticks(fontsize=20,weight='bold')\n",
        "plt.plot([0, 1], [0, 1], 'k--',linewidth=5)\n",
        "plt.plot(fpr, tpr, color='#008929', label='AUC = {:.3f}'.format(roc_auc),linewidth=5)\n",
        "plt.legend(loc='best', frameon=True, prop={'size':15,'weight':'bold'})\n",
        "plt.xlim([-0.05, 1])\n",
        "plt.ylim([0, 1.05])\n",
        "plt.xlabel('False positive rate',fontsize=22,color='brown',weight='bold')\n",
        "plt.ylabel('True positive rate',fontsize=22,color='brown',weight='bold')\n",
        "plt.title('DenseNet121+LR',fontsize=25,color='brown',weight='bold')\n",
        "plt.grid(False)\n",
        "\n",
        "plt.savefig(\"ROC_DenseNet121+LR.pdf\", bbox_inches='tight')\n",
        "files.download(\"ROC_DenseNet121+LR.pdf\")\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}